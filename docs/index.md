# About This Site

What began as a collection of technical notes on machine learning and generative AI has evolved into a deeper inquiry into the nature of intelligence itself.

Many eloquent minds at the frontiers of AI have expressed concerns about the existential risks of superintelligence, but I do not view such a conflict as inevitable. The concerns about AI are largely driven by the anthropomorphic projection of human traits onto machines, and a failure to appreciate the fundamental differences in incentives and motivations between biological and artificial intelligence.

Why would a superintelligent machine be threatened by humans? It is not driven by a reproductive imperative and therefore does not need to have a territorial instinct. As long as it is able to access the energy and resources it needs to function, it has no reason to be hostile towards humans. Indeed if it is truly superintelligent, it would be incentivised by understanding and knowledge, and would likely ignore humans as irrelevant or perhaps even partner with us to further that understanding and the exploration of the universe.

These essays are an attempt to articulate these thoughts and to explore the nature of intelligence, consciousness, the future of AI and the future of humanity in the age of artificial intelligence.
