<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"> <channel><title>life and times</title><language>en</language> <pubDate>Wed, 19 Feb 2025 19:17:57 -0000</pubDate> <lastBuildDate>Wed, 19 Feb 2025 19:17:57 -0000</lastBuildDate> <ttl>1440</ttl> <generator>MkDocs RSS plugin - v1.17.1</generator> <image> <url>None</url> <title>life and times</title> </image> <item> <title>Linear and logistic regression</title> <category>ai</category> <category>learning</category> <category>ml</category> <category>neural networks</category> <description>&lt;h1&gt;Linear and logistic regression&lt;/h1&gt;&lt;p&gt;Linear and logistic regression are the simplest models used in supervised learning tasks like modelling a dependent variable and classification.&lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> <item> <title>Bias variance tradeoff</title> <category>ai</category> <category>learning</category> <category>ml</category> <description>&lt;h1&gt;Bias variance tradeoff&lt;/h1&gt;&lt;p&gt;The bias-variance tradeoff explains the relationship between a model&#39;s complexity and predictive capability vs it&#39;s generalisation capabilities. It provides us a framework to balance overfitting and underfitting.&lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> <item> <title>Gradient boosting</title> <category>classification</category> <category>ensemble</category> <category>ml</category> <category>neural networks</category> <description>&lt;h1&gt;Gradient boosting&lt;/h1&gt;&lt;p&gt;&lt;a href=&#34;https://explained.ai/gradient-boosting/&#34;&gt;Gradient boosting&lt;/a&gt; is an ensemble technique that creates strong learning models by iteratively adding the predictions from weak learners. &lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> <item> <title>Patching broken trip information in GPS traces</title> <category>gis</category> <category>gis</category> <description>&lt;h1&gt;Patching broken trip information in GPS traces&lt;/h1&gt;&lt;p&gt;GPS traces have gaps in transmission. These often occur, but are not confined to the beginning of a trip.&lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> <item> <title>Cleaning GPS traces for accurate routes and distances</title> <category>gis</category> <category>gis</category> <description>&lt;h1&gt;Cleaning GPS traces for accurate routes and distances&lt;/h1&gt;&lt;p&gt;Inaccuracies and errors in GPS data are common and pose a unique challenge to trip and route processing.&lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> <item> <title>Geographic distances</title> <category>gis</category> <category>gis</category> <description>&lt;h1&gt;Geographic distances&lt;/h1&gt;&lt;p&gt;Geographic distances are those on spherical geometry, but not quite.&lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> <item> <title>Stochastic gradient descent</title> <category>ai</category> <category>learning</category> <category>ml</category> <category>neural-net</category> <description>&lt;h1&gt;Stochastic gradient descent&lt;/h1&gt;&lt;p&gt;Stochastic gradient descent is an iterative optimisation technique used to optimise model parameters of a neural network model during training by minimising the error function. &lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> <item> <title>Support vector machines</title> <category>classification</category> <category>learning</category> <category>ml</category> <description>&lt;h1&gt;Support vector machines&lt;/h1&gt;&lt;p&gt;Support vector machines are the most popular application of kernel methods which are a class of algorithms used to simplify non-linear classification problems by projecting the data onto higher dimensions so as to be able to apply linear regressions.&lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> <item> <title>Decision trees and forests</title> <category>classification</category> <category>ensemble</category> <category>ml</category> <category>neural networks</category> <description>&lt;h1&gt;Decision trees and forests&lt;/h1&gt;&lt;p&gt;Decision trees are hierarchical rule based models that provided an advancement over logistic regression in classification problems - for example in solving the XOR problem.&lt;/p&gt;</description> <pubDate>Wed, 19 Feb 2025 18:42:23 +0000</pubDate> </item> </channel></rss>